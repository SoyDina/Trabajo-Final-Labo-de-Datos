{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.utils import np_utils, plot_model\n",
    "#from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = np.load(\"data_pca/X_pca_3clases.npy\")\n",
    "X_test_pca = np.load(\"data_pca/X_pca_test_3clases.npy\")\n",
    "y_train_pca = np.load(\"data_pca/y_train_rec_3clases.npy\")\n",
    "y_test_pca = np.load(\"data_pca/y_test_3clases.npy\")\n",
    "y_train_oh = np.load(\"data_pca/y_train_oh_3clases\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo secuencial (primero esta vacio)\n",
    "model_simple = Sequential()\n",
    "\n",
    "# Agregamos una capa de 10 perceptrones con activación logística (softmax)\n",
    "model_simple.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# la función Dense() crea una capa de 10 nodos (perceptrones) que está fully connected, es decir que todas las entradas obtienen un peso para todos los nodos\n",
    "# por lo que la cantidad de pesos en este caso sería 784x10 (784 pesos, uno por cada entrada del vector input para cada uno de los perceptrones)\n",
    "model_simple.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model_simple.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=10, # ignorar esto porque excede el contenido de la clase\n",
    "          verbose=1, # para que nos vaya indicando por qué instancia de entrenamiento va\n",
    "          validation_data=(X_test, Y_test)) # es análogo al .fit() de las regresiones que vimos en otras clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "salida = model_simple.predict(X_test[0:1]) # análogo al .predict_proba() que de sklearn\n",
    "\n",
    "print('Shape de la salida:',salida.shape)\n",
    "print('Salida:',salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "modular-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(alpha=1, hidden_layer_sizes=500, max_iter=1000)\n",
    "\n",
    "clf.fit(X_train_pca, y_train_pca)\n",
    "score = clf.score(X_test_pca, y_test_pca)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "y_test = y_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elect-feedback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Micro Precision: 0.68\n",
      "Micro Recall: 0.68\n",
      "Micro F1-score: 0.68\n",
      "\n",
      "Macro Precision: 0.71\n",
      "Macro Recall: 0.68\n",
      "Macro F1-score: 0.65\n",
      "\n",
      "Weighted Precision: 0.75\n",
      "Weighted Recall: 0.68\n",
      "Weighted F1-score: 0.67\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.92      0.41      0.57       234\n",
      "    Bacteria       0.73      0.89      0.81       242\n",
      "       Virus       0.49      0.74      0.59       148\n",
      "\n",
      "    accuracy                           0.68       624\n",
      "   macro avg       0.71      0.68      0.65       624\n",
      "weighted avg       0.75      0.68      0.67       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_pca, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Bacteria', 'Virus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-disposal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
